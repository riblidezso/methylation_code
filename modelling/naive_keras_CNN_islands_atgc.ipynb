{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Very naive deep learning on the vector of surrounding bases\n",
    "\n",
    "---\n",
    "\n",
    "### Data\n",
    "\n",
    "Naive feature vectors. The original sequence of validation/test and train data does not overlap! ( but train data points can overlap with train data points, and test-validation can overlap with test-validation data ) This overlapping does not lead to unintentional label leakage!\n",
    "\n",
    "\n",
    "\n",
    "### Notes\n",
    "\n",
    "\n",
    "- better than acgt\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instruct theano to use gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['THEANO_FLAGS']='device=gpu'\n",
    "\n",
    "import sys\n",
    "sys.path.append('../my_modules')\n",
    "from loading_utils import read_my_data\n",
    "\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os,subprocess\n",
    "workdir='/mnt/Data1/ribli/methylation_code/modelling'\n",
    "subprocess.call(['mkdir',workdir])\n",
    "os.chdir(workdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data... \n",
      "Loading data... \n"
     ]
    }
   ],
   "source": [
    "train_id,train_x,train_y = read_my_data(\n",
    "    fname='../prepare_data/big_train_feat_vect.csv')\n",
    "test_id,test_x,test_y = read_my_data(\n",
    "    fname='../prepare_data/big_test_feat_vect.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "annot=pd.read_csv('../explore_data/relevant_annotations.csv',sep='\\t',header=None)\n",
    "annot.columns=['id','Regulatory_Feature_Group','Relation_to_UCSC_CpG_Island',\n",
    "    'Strand','Infinium_Design_Type','Random_Loci','Methyl27_Loci']\n",
    "annot.fillna(0,inplace=True)\n",
    "train_merged=pd.DataFrame(train_id,columns=['id']).merge(annot,on=['id'])\n",
    "test_merged=pd.DataFrame(test_id,columns=['id']).merge(annot,on=['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select inidces for islands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cg_exl_idx=np.array([x[499]==2 and x[500]==3 for x in train_x])\n",
    "annot_idx=np.array(np.zeros(len(train_x)),dtype=bool)\n",
    "annot_idx[train_merged[train_merged.Relation_to_UCSC_CpG_Island=='Island'].index]=True\n",
    "train_idx=cg_exl_idx & annot_idx\n",
    "train_idx_0=cg_exl_idx & annot_idx & (train_y ==0)\n",
    "train_idx_1=cg_exl_idx & annot_idx & (train_y ==1)\n",
    "\n",
    "\n",
    "cg_exl_idx=np.array([x[499]==2 and x[500]==3 for x in test_x])\n",
    "annot_idx=np.array(np.zeros(len(test_x)),dtype=bool)\n",
    "annot_idx[test_merged[test_merged.Relation_to_UCSC_CpG_Island=='Island'].index]=True\n",
    "test_idx=cg_exl_idx & annot_idx\n",
    "test_idx_0=cg_exl_idx & annot_idx & (test_y==0)\n",
    "test_idx_1=cg_exl_idx & annot_idx & (test_y==1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape x data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make it image like\n",
    "train_x,test_x=[x.reshape((-1,1,1000,1)) for x in (train_x,test_x)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "def fit_keras_model(model,train_x,train_y,test_x,test_y,validation_split=0.05):\n",
    "    start=time.time()\n",
    "    \n",
    "    #callbacks\n",
    "    best_model=ModelCheckpoint('best_model',save_best_only=True,verbose=1)\n",
    "    early_stop=EarlyStopping(patience=7,verbose=1)\n",
    "    \n",
    "    #train it\n",
    "    callb_hist=model.fit(train_x,train_y,nb_epoch = 100,\n",
    "                         show_accuracy=True,verbose=1,\n",
    "                        validation_split=validation_split,\n",
    "                        callbacks=[best_model,early_stop])\n",
    "    #predict\n",
    "    model.load_weights('best_model')\n",
    "    train_pred=model.predict_classes(train_x).ravel()\n",
    "    test_pred=model.predict_classes(test_x).ravel()\n",
    "\n",
    "    #check errors\n",
    "    print 'train score:',list((train_pred==train_y)).count(True)/float(len(train_y))\n",
    "    print 'test score:',list((test_pred==test_y)).count(True)/float(len(test_y))\n",
    "\n",
    "    print 'It took:',time.time()-start    \n",
    "    return train_pred,test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "bal_train_x=np.concatenate([train_x[train_idx_0][:np.sum(train_idx_1)],train_x[train_idx_1]])\n",
    "bal_train_y=np.concatenate([train_y[train_idx_0][:np.sum(train_idx_1)],train_y[train_idx_1]])\n",
    "\n",
    "bal_test_x=np.concatenate([test_x[test_idx_0][:np.sum(test_idx_1)],test_x[test_idx_1]])\n",
    "bal_test_y=np.concatenate([test_y[test_idx_0][:np.sum(test_idx_1)],test_y[test_idx_1]])\n",
    "\n",
    "\n",
    "#shuffle them\n",
    "#set seed to make the selection reproducible\n",
    "rng=np.random.RandomState(42)\n",
    "new_idx=rng.permutation(len(bal_train_y))\n",
    "bal_train_x=bal_train_x[new_idx]\n",
    "bal_train_y=bal_train_y[new_idx]\n",
    "\n",
    "new_idx=rng.permutation(len(bal_test_y))\n",
    "bal_test_x=bal_test_x[new_idx]\n",
    "bal_test_y=bal_test_y[new_idx]\n",
    "\n",
    "print np.mean(bal_train_y)\n",
    "print np.mean(bal_test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make acgt to atgc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bal_train_x[bal_train_x==4]=5\n",
    "bal_train_x[bal_train_x==2]=4\n",
    "bal_train_x[bal_train_x==5]=2\n",
    "\n",
    "bal_test_x[bal_test_x==4]=5\n",
    "bal_test_x[bal_test_x==2]=4\n",
    "bal_test_x[bal_test_x==5]=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Convnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D,MaxPooling2D\n",
    "\n",
    "input_dim=train_x.shape[2]\n",
    "activation='relu'\n",
    "loss='binary_crossentropy'\n",
    "optimizer='adadelta'\n",
    "init='uniform'\n",
    "pool_size=(8,1)\n",
    "window_size=5\n",
    "dense_n=64\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#Convolution layer 1\n",
    "model.add(Convolution2D(20,window_size,1, border_mode='valid',input_shape=(1,input_dim,1)))\n",
    "model.add(Activation(activation))\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "#Convolution layer 2\n",
    "model.add(Convolution2D(50,window_size,1, border_mode='valid'))\n",
    "model.add(Activation(activation))\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "#Dense layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(dense_n,activation=activation))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "#final layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#compile model\n",
    "model.compile(loss=loss,optimizer=optimizer,class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17651 samples, validate on 4413 samples\n",
      "Epoch 1/100\n",
      "17651/17651 [==============================] - 7s - loss: 0.7360 - acc: 0.5498 - val_loss: 0.6215 - val_acc: 0.7188\n",
      "Epoch 00000: val_loss improved from inf to 0.62145, saving model to best_model\n",
      "Epoch 2/100\n",
      "17651/17651 [==============================] - 7s - loss: 0.6515 - acc: 0.6396 - val_loss: 0.6728 - val_acc: 0.5957\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 3/100\n",
      "17651/17651 [==============================] - 7s - loss: 0.5883 - acc: 0.6929 - val_loss: 0.5495 - val_acc: 0.7380\n",
      "Epoch 00002: val_loss improved from 0.62145 to 0.54955, saving model to best_model\n",
      "Epoch 4/100\n",
      "17651/17651 [==============================] - 7s - loss: 0.5547 - acc: 0.7171 - val_loss: 0.5519 - val_acc: 0.7206\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 5/100\n",
      "17651/17651 [==============================] - 7s - loss: 0.5384 - acc: 0.7332 - val_loss: 0.5670 - val_acc: 0.7043\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 6/100\n",
      "17651/17651 [==============================] - 7s - loss: 0.5158 - acc: 0.7494 - val_loss: 0.5056 - val_acc: 0.7528\n",
      "Epoch 00005: val_loss improved from 0.54955 to 0.50560, saving model to best_model\n",
      "Epoch 7/100\n",
      "17651/17651 [==============================] - 7s - loss: 0.5012 - acc: 0.7537 - val_loss: 0.4906 - val_acc: 0.7564\n",
      "Epoch 00006: val_loss improved from 0.50560 to 0.49060, saving model to best_model\n",
      "Epoch 8/100\n",
      "17651/17651 [==============================] - 7s - loss: 0.5010 - acc: 0.7530 - val_loss: 0.7512 - val_acc: 0.5690\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 9/100\n",
      "17651/17651 [==============================] - 7s - loss: 0.4931 - acc: 0.7619 - val_loss: 0.4581 - val_acc: 0.7886\n",
      "Epoch 00008: val_loss improved from 0.49060 to 0.45807, saving model to best_model\n",
      "Epoch 10/100\n",
      "17651/17651 [==============================] - 7s - loss: 0.4737 - acc: 0.7754 - val_loss: 0.4256 - val_acc: 0.8031\n",
      "Epoch 00009: val_loss improved from 0.45807 to 0.42559, saving model to best_model\n",
      "Epoch 11/100\n",
      "17651/17651 [==============================] - 7s - loss: 0.4565 - acc: 0.7814 - val_loss: 0.4567 - val_acc: 0.7816\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 12/100\n",
      "17651/17651 [==============================] - 7s - loss: 0.4508 - acc: 0.7882 - val_loss: 0.5778 - val_acc: 0.6889\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 13/100\n",
      "17651/17651 [==============================] - 7s - loss: 0.4506 - acc: 0.7830 - val_loss: 0.5829 - val_acc: 0.6988\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 14/100\n",
      "17651/17651 [==============================] - 7s - loss: 0.4330 - acc: 0.7972 - val_loss: 0.4512 - val_acc: 0.7956\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 15/100\n",
      "17651/17651 [==============================] - 7s - loss: 0.4279 - acc: 0.8018 - val_loss: 0.5573 - val_acc: 0.7437\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 16/100\n",
      "17651/17651 [==============================] - 7s - loss: 0.4166 - acc: 0.8068 - val_loss: 0.5329 - val_acc: 0.7591\n",
      "Epoch 00015: val_loss did not improve\n",
      "Epoch 17/100\n",
      "17651/17651 [==============================] - 7s - loss: 0.3986 - acc: 0.8164 - val_loss: 0.4168 - val_acc: 0.8137\n",
      "Epoch 00016: val_loss improved from 0.42559 to 0.41680, saving model to best_model\n",
      "Epoch 18/100\n",
      "17651/17651 [==============================] - 7s - loss: 0.3957 - acc: 0.8179 - val_loss: 0.4492 - val_acc: 0.7820\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 19/100\n",
      "17651/17651 [==============================] - 7s - loss: 0.3867 - acc: 0.8222 - val_loss: 0.5058 - val_acc: 0.7516\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 20/100\n",
      "17651/17651 [==============================] - 7s - loss: 0.3715 - acc: 0.8300 - val_loss: 0.5393 - val_acc: 0.7308\n",
      "Epoch 00019: val_loss did not improve\n",
      "Epoch 21/100\n",
      "17651/17651 [==============================] - 7s - loss: 0.3650 - acc: 0.8372 - val_loss: 0.4655 - val_acc: 0.7954\n",
      "Epoch 00020: val_loss did not improve\n",
      "Epoch 22/100\n",
      "17651/17651 [==============================] - 7s - loss: 0.3479 - acc: 0.8427 - val_loss: 0.4125 - val_acc: 0.8083\n",
      "Epoch 00021: val_loss improved from 0.41680 to 0.41247, saving model to best_model\n",
      "Epoch 23/100\n",
      "17651/17651 [==============================] - 7s - loss: 0.3269 - acc: 0.8560 - val_loss: 0.9798 - val_acc: 0.6175\n",
      "Epoch 00022: val_loss did not improve\n",
      "Epoch 24/100\n",
      "17651/17651 [==============================] - 7s - loss: 0.3312 - acc: 0.8531 - val_loss: 0.4212 - val_acc: 0.8081\n",
      "Epoch 00023: val_loss did not improve\n",
      "Epoch 25/100\n",
      "17651/17651 [==============================] - 7s - loss: 0.3135 - acc: 0.8624 - val_loss: 0.4699 - val_acc: 0.7972\n",
      "Epoch 00024: val_loss did not improve\n",
      "Epoch 26/100\n",
      "17651/17651 [==============================] - 7s - loss: 0.2784 - acc: 0.8802 - val_loss: 0.8853 - val_acc: 0.6191\n",
      "Epoch 00025: val_loss did not improve\n",
      "Epoch 27/100\n",
      "17651/17651 [==============================] - 7s - loss: 0.2739 - acc: 0.8842 - val_loss: 0.8524 - val_acc: 0.6814\n",
      "Epoch 00026: val_loss did not improve\n",
      "Epoch 28/100\n",
      "17651/17651 [==============================] - 7s - loss: 0.2556 - acc: 0.8905 - val_loss: 0.6002 - val_acc: 0.7455\n",
      "Epoch 00027: val_loss did not improve\n",
      "Epoch 29/100\n",
      "17651/17651 [==============================] - 7s - loss: 0.2381 - acc: 0.9025 - val_loss: 0.6708 - val_acc: 0.7220\n",
      "Epoch 00028: val_loss did not improve\n",
      "Epoch 30/100\n",
      "17651/17651 [==============================] - 7s - loss: 0.2265 - acc: 0.9049 - val_loss: 0.4989 - val_acc: 0.7915\n",
      "Epoch 00029: val_loss did not improve\n",
      "Epoch 00029: early stopping\n",
      "22064/22064 [==============================] - 3s     \n",
      "1010/1010 [==============================] - 0s     \n",
      "train score: 0.872008701958\n",
      "test score: 0.79504950495\n",
      "It took: 224.977956772\n",
      "\n",
      "prediction balance:\n",
      "0.552936910805\n",
      "0.564356435644\n"
     ]
    }
   ],
   "source": [
    "train_pred,test_pred=fit_keras_model(\n",
    "    model,bal_train_x,bal_train_y,bal_test_x,bal_test_y,validation_split=0.2)\n",
    "\n",
    "print '\\nprediction balance:'\n",
    "print np.mean(train_pred)\n",
    "print np.mean(test_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
