{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Very naive deep learning on the vector of surrounding bases\n",
    "\n",
    "---\n",
    "\n",
    "### Data\n",
    "\n",
    "Naive feature vectors. The original sequence of validation/test and train data does not overlap! ( but train data points can overlap with train data points, and test-validation can overlap with test-validation data ) This overlapping does not lead to unintentional label leakage!\n",
    "\n",
    "\n",
    "\n",
    "### Notes\n",
    "\n",
    "- Worse than single channel\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instruct theano to use gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['THEANO_FLAGS']='device=gpu'\n",
    "\n",
    "import sys\n",
    "sys.path.append('../my_modules')\n",
    "from loading_utils import read_my_data\n",
    "\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os,subprocess\n",
    "workdir='/mnt/Data1/ribli/methylation_code/modelling'\n",
    "subprocess.call(['mkdir',workdir])\n",
    "os.chdir(workdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data... \n",
      "Loading data... \n"
     ]
    }
   ],
   "source": [
    "train_id,train_x,train_y = read_my_data(\n",
    "    fname='../prepare_data/big_train_feat_vect.csv')\n",
    "test_id,test_x,test_y = read_my_data(\n",
    "    fname='../prepare_data/big_test_feat_vect.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "annot=pd.read_csv('../explore_data/relevant_annotations.csv',sep='\\t',header=None)\n",
    "annot.columns=['id','Regulatory_Feature_Group','Relation_to_UCSC_CpG_Island',\n",
    "    'Strand','Infinium_Design_Type','Random_Loci','Methyl27_Loci']\n",
    "annot.fillna(0,inplace=True)\n",
    "train_merged=pd.DataFrame(train_id,columns=['id']).merge(annot,on=['id'])\n",
    "test_merged=pd.DataFrame(test_id,columns=['id']).merge(annot,on=['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select inidces for islands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cg_exl_idx=np.array([x[499]==2 and x[500]==3 for x in train_x])\n",
    "annot_idx=np.array(np.zeros(len(train_x)),dtype=bool)\n",
    "annot_idx[train_merged[train_merged.Relation_to_UCSC_CpG_Island=='Island'].index]=True\n",
    "train_idx=cg_exl_idx & annot_idx\n",
    "train_idx_0=cg_exl_idx & annot_idx & (train_y ==0)\n",
    "train_idx_1=cg_exl_idx & annot_idx & (train_y ==1)\n",
    "\n",
    "\n",
    "cg_exl_idx=np.array([x[499]==2 and x[500]==3 for x in test_x])\n",
    "annot_idx=np.array(np.zeros(len(test_x)),dtype=bool)\n",
    "annot_idx[test_merged[test_merged.Relation_to_UCSC_CpG_Island=='Island'].index]=True\n",
    "test_idx=cg_exl_idx & annot_idx\n",
    "test_idx_0=cg_exl_idx & annot_idx & (test_y==0)\n",
    "test_idx_1=cg_exl_idx & annot_idx & (test_y==1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "bal_train_x=np.concatenate([train_x[train_idx_0][:np.sum(train_idx_1)],train_x[train_idx_1]])\n",
    "bal_train_y=np.concatenate([train_y[train_idx_0][:np.sum(train_idx_1)],train_y[train_idx_1]])\n",
    "\n",
    "bal_test_x=np.concatenate([test_x[test_idx_0][:np.sum(test_idx_1)],test_x[test_idx_1]])\n",
    "bal_test_y=np.concatenate([test_y[test_idx_0][:np.sum(test_idx_1)],test_y[test_idx_1]])\n",
    "\n",
    "\n",
    "#shuffle them\n",
    "#set seed to make the selection reproducible\n",
    "rng=np.random.RandomState(42)\n",
    "new_idx=rng.permutation(len(bal_train_y))\n",
    "bal_train_x=bal_train_x[new_idx]\n",
    "bal_train_y=bal_train_y[new_idx]\n",
    "\n",
    "new_idx=rng.permutation(len(bal_test_y))\n",
    "bal_test_x=bal_test_x[new_idx]\n",
    "bal_test_y=bal_test_y[new_idx]\n",
    "\n",
    "print np.mean(bal_train_y)\n",
    "print np.mean(bal_test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encode them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(np.concatenate([bal_train_x.flatten(),bal_test_x.flatten()]))\n",
    "one_hot_train_x=lb.transform(bal_train_x.flatten()).reshape((-1,5,1000,1))\n",
    "one_hot_test_x=lb.transform(bal_test_x.flatten()).reshape((-1,5,1000,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build convnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 670 (CNMeM is disabled, CuDNN not available)\n",
      "/mnt/Data1/ribli/tools/anaconda/lib/python2.7/site-packages/theano/tensor/signal/downsample.py:5: UserWarning: downsample module has been moved to the pool module.\n",
      "  warnings.warn(\"downsample module has been moved to the pool module.\")\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D,MaxPooling2D\n",
    "\n",
    "input_dim=one_hot_train_x.shape[2]\n",
    "activation='relu'\n",
    "loss='binary_crossentropy'\n",
    "optimizer='adadelta'\n",
    "init='uniform'\n",
    "pool_size=(8,1)\n",
    "window_size=5\n",
    "dense_n=64\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#Convolution layer 1\n",
    "model.add(Convolution2D(20,window_size,1, border_mode='valid',input_shape=(5,input_dim,1)))\n",
    "model.add(Activation(activation))\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "#Convolution layer 2\n",
    "model.add(Convolution2D(50,window_size,1, border_mode='valid'))\n",
    "model.add(Activation(activation))\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "#Dense layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(dense_n,activation=activation))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "#final layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#compile model\n",
    "model.compile(loss=loss,optimizer=optimizer,class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "\n",
    "def fit_keras_model(model,train_x,train_y,test_x,test_y,validation_split=0.05):\n",
    "    start=time.time()\n",
    "    \n",
    "    #callbacks\n",
    "    best_model=ModelCheckpoint('best_model',save_best_only=True,verbose=1)\n",
    "    early_stop=EarlyStopping(patience=7,verbose=1)\n",
    "    \n",
    "    #train it\n",
    "    callb_hist=model.fit(train_x,train_y,nb_epoch = 100,\n",
    "                         show_accuracy=True,verbose=1,\n",
    "                        validation_split=validation_split,\n",
    "                        callbacks=[best_model,early_stop])\n",
    "    #predict\n",
    "    model.load_weights('best_model')\n",
    "    train_pred=model.predict_classes(train_x).ravel()\n",
    "    test_pred=model.predict_classes(test_x).ravel()\n",
    "\n",
    "    #check errors\n",
    "    print 'train score:',list((train_pred==train_y)).count(True)/float(len(train_y))\n",
    "    print 'test score:',list((test_pred==test_y)).count(True)/float(len(test_y))\n",
    "\n",
    "    print 'It took:',time.time()-start    \n",
    "    return train_pred,test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17651 samples, validate on 4413 samples\n",
      "Epoch 1/100\n",
      "17651/17651 [==============================] - 7s - loss: 0.7046 - acc: 0.5098 - val_loss: 0.6929 - val_acc: 0.5042\n",
      "Epoch 00000: val_loss improved from inf to 0.69290, saving model to best_model\n",
      "Epoch 2/100\n",
      "17651/17651 [==============================] - 7s - loss: 0.6910 - acc: 0.5316 - val_loss: 0.6860 - val_acc: 0.5350\n",
      "Epoch 00001: val_loss improved from 0.69290 to 0.68596, saving model to best_model\n",
      "Epoch 3/100\n",
      "17651/17651 [==============================] - 7s - loss: 0.6841 - acc: 0.5572 - val_loss: 0.6744 - val_acc: 0.6254\n",
      "Epoch 00002: val_loss improved from 0.68596 to 0.67441, saving model to best_model\n",
      "Epoch 4/100\n",
      "17651/17651 [==============================] - 7s - loss: 0.6758 - acc: 0.5761 - val_loss: 0.6456 - val_acc: 0.6334\n",
      "Epoch 00003: val_loss improved from 0.67441 to 0.64556, saving model to best_model\n",
      "Epoch 5/100\n",
      "17651/17651 [==============================] - 7s - loss: 0.6655 - acc: 0.5918 - val_loss: 0.6693 - val_acc: 0.5797\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 6/100\n",
      "17651/17651 [==============================] - 7s - loss: 0.6511 - acc: 0.6129 - val_loss: 0.6340 - val_acc: 0.6368\n",
      "Epoch 00005: val_loss improved from 0.64556 to 0.63401, saving model to best_model\n",
      "Epoch 7/100\n",
      "17651/17651 [==============================] - 7s - loss: 0.6416 - acc: 0.6251 - val_loss: 0.6257 - val_acc: 0.6467\n",
      "Epoch 00006: val_loss improved from 0.63401 to 0.62572, saving model to best_model\n",
      "Epoch 8/100\n",
      "17651/17651 [==============================] - 7s - loss: 0.6364 - acc: 0.6307 - val_loss: 0.6242 - val_acc: 0.6472\n",
      "Epoch 00007: val_loss improved from 0.62572 to 0.62418, saving model to best_model\n",
      "Epoch 9/100\n",
      "17651/17651 [==============================] - 7s - loss: 0.6314 - acc: 0.6413 - val_loss: 0.6221 - val_acc: 0.6535\n",
      "Epoch 00008: val_loss improved from 0.62418 to 0.62207, saving model to best_model\n",
      "Epoch 10/100\n",
      "17651/17651 [==============================] - 7s - loss: 0.6158 - acc: 0.6565 - val_loss: 0.6382 - val_acc: 0.6499\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 11/100\n",
      "17651/17651 [==============================] - 7s - loss: 0.6047 - acc: 0.6738 - val_loss: 0.6110 - val_acc: 0.6644\n",
      "Epoch 00010: val_loss improved from 0.62207 to 0.61100, saving model to best_model\n",
      "Epoch 12/100\n",
      "17651/17651 [==============================] - 7s - loss: 0.5939 - acc: 0.6793 - val_loss: 0.6153 - val_acc: 0.6658\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 13/100\n",
      "17651/17651 [==============================] - 7s - loss: 0.5751 - acc: 0.6961 - val_loss: 0.6130 - val_acc: 0.6617\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 14/100\n",
      "17651/17651 [==============================] - 7s - loss: 0.5673 - acc: 0.7021 - val_loss: 0.6648 - val_acc: 0.5991\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 15/100\n",
      "17651/17651 [==============================] - 7s - loss: 0.5519 - acc: 0.7171 - val_loss: 0.6957 - val_acc: 0.5894\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 16/100\n",
      "17651/17651 [==============================] - 7s - loss: 0.5306 - acc: 0.7304 - val_loss: 0.6388 - val_acc: 0.6504\n",
      "Epoch 00015: val_loss did not improve\n",
      "Epoch 17/100\n",
      "17651/17651 [==============================] - 7s - loss: 0.5141 - acc: 0.7439 - val_loss: 0.6606 - val_acc: 0.6277\n",
      "Epoch 00016: val_loss did not improve\n",
      "Epoch 18/100\n",
      "17651/17651 [==============================] - 7s - loss: 0.4969 - acc: 0.7601 - val_loss: 0.6624 - val_acc: 0.6402\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 19/100\n",
      "17651/17651 [==============================] - 7s - loss: 0.4584 - acc: 0.7826 - val_loss: 0.7772 - val_acc: 0.6107\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 00018: early stopping\n",
      "22064/22064 [==============================] - 4s     \n",
      "1010/1010 [==============================] - 0s     \n",
      "22064\n",
      "1010\n",
      "1010\n",
      "1010\n",
      "train score: 0.711249093546\n",
      "test score: 0.631683168317\n",
      "It took: 154.078707933\n",
      "\n",
      "prediction balance:\n",
      "0.486811094996\n",
      "0.476237623762\n"
     ]
    }
   ],
   "source": [
    "train_pred,test_pred=fit_keras_model(\n",
    "    model,one_hot_train_x,bal_train_y,one_hot_test_x,bal_test_y,validation_split=0.2)\n",
    "\n",
    "print '\\nprediction balance:'\n",
    "print np.mean(train_pred)\n",
    "print np.mean(test_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
