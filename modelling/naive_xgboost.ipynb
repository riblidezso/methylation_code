{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Very naive learning on the vector of surrounding bases with xgboost\n",
    "\n",
    "---\n",
    "\n",
    "### Analysis\n",
    "\n",
    "I will try to naively predict the mehtylation value (0,1) based on naive sequence context feauture vectors.\n",
    "\n",
    "I will use xgboost, a sophisticated library for gradient boosting, which is used to win many kaggle competitions.\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "### Conlcusions\n",
    "\n",
    "- suprisingly, with brutal overfitting generalization still improves\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import xgboost as xgb\n",
    "\n",
    "import sys\n",
    "sys.path.append('../my_modules/')\n",
    "from loading_utils import read_my_data,create_sets\n",
    "\n",
    "import os,subprocess\n",
    "workdir='/nagyvinyok/adat84/sotejedlik/ribli/methylation_code/modelling'\n",
    "subprocess.call(['mkdir',workdir])\n",
    "os.chdir(workdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data... \n"
     ]
    }
   ],
   "source": [
    "x,y= read_my_data(fname='../prepare_data/meth_feat_vect.csv')\n",
    "\n",
    "#select the whole dataset\n",
    "(train_x,train_y),(valid_x,valid_y),(test_x,test_y)= create_sets(\n",
    "    x,y,N_train=50000,N_valid=5000,N_test=5000,length=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create xgboost matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix( train_x, label=train_y)\n",
    "dvalid = xgb.DMatrix( valid_x, label=valid_y)\n",
    "dtest = xgb.DMatrix( test_x, label=test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With modest overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until eval error hasn't decreased in 100 rounds.\n",
      "[0]\ttrain-error:0.415020\teval-error:0.415200\n",
      "[50]\ttrain-error:0.245100\teval-error:0.277000\n",
      "[100]\ttrain-error:0.219760\teval-error:0.248000\n",
      "[150]\ttrain-error:0.207740\teval-error:0.244400\n",
      "[200]\ttrain-error:0.199100\teval-error:0.241000\n",
      "[250]\ttrain-error:0.191360\teval-error:0.238400\n",
      "[300]\ttrain-error:0.182300\teval-error:0.235400\n",
      "[350]\ttrain-error:0.173160\teval-error:0.232200\n",
      "[400]\ttrain-error:0.165160\teval-error:0.230200\n",
      "[450]\ttrain-error:0.156560\teval-error:0.231600\n",
      "Stopping. Best iteration:\n",
      "[395]\ttrain-error:0.165940\teval-error:0.229000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param = {'max_depth':4,\n",
    "         'eta':0.1,\n",
    "         'min_child_weight':50,\n",
    "         'colsample_bytree':0.8,\n",
    "         'subsample':0.6,\n",
    "         'silent':1,\n",
    "         'objective': \"binary:logistic\",\n",
    "         'eval_metric': 'error',\n",
    "         'nthread':8}\n",
    "\n",
    "evallist  = [(dtrain,'train'),(dvalid,'eval')]\n",
    "\n",
    "#train\n",
    "num_round = 500\n",
    "bst = xgb.train(param,\n",
    "                dtrain,\n",
    "                evals=evallist,\n",
    "                num_boost_round=num_round,\n",
    "                early_stopping_rounds=100,\n",
    "                verbose_eval=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.85056\n",
      "validation score: 0.7682\n",
      "test score: 0.7646\n"
     ]
    }
   ],
   "source": [
    "print 'train score:',list(map(round,bst.predict(dtrain))==train_y).count(True)/float(len(train_y))\n",
    "print 'validation score:',list(map(round,bst.predict(dvalid))==valid_y).count(True)/float(len(valid_y))\n",
    "print 'test score:',list(map(round,bst.predict(dtest))==test_y).count(True)/float(len(test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With brutal overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until eval error hasn't decreased in 5000 rounds.\n",
      "[0]\ttrain-error:0.388680\teval-error:0.417600\n",
      "[500]\ttrain-error:0.150880\teval-error:0.235800\n",
      "[1000]\ttrain-error:0.111840\teval-error:0.227200\n",
      "[1500]\ttrain-error:0.072180\teval-error:0.226400\n",
      "[2000]\ttrain-error:0.037960\teval-error:0.223400\n",
      "[2500]\ttrain-error:0.016060\teval-error:0.220000\n",
      "[3000]\ttrain-error:0.007140\teval-error:0.220400\n",
      "[3500]\ttrain-error:0.002600\teval-error:0.218400\n",
      "[4000]\ttrain-error:0.001140\teval-error:0.218000\n",
      "[4500]\ttrain-error:0.000280\teval-error:0.218400\n",
      "[4999]\ttrain-error:0.000120\teval-error:0.216000\n"
     ]
    }
   ],
   "source": [
    "param = {'max_depth':7,\n",
    "         'eta':0.01,\n",
    "         'min_child_weight':1,\n",
    "         'colsample_bytree':1,\n",
    "         'subsample':1,\n",
    "         'silent':1,\n",
    "         'objective': \"binary:logistic\",\n",
    "         'eval_metric': 'error',\n",
    "         'nthread':8}\n",
    "\n",
    "evallist  = [(dtrain,'train'),(dvalid,'eval')]\n",
    "\n",
    "#train\n",
    "num_round = 5000\n",
    "bst = xgb.train(param,\n",
    "                dtrain,\n",
    "                evals=evallist,\n",
    "                num_boost_round=num_round,\n",
    "                early_stopping_rounds=5000,\n",
    "                verbose_eval=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.99988\n",
      "validation score: 0.784\n",
      "test score: 0.7834\n"
     ]
    }
   ],
   "source": [
    "print 'train score:',list(map(round,bst.predict(dtrain))==train_y).count(True)/float(len(train_y))\n",
    "print 'validation score:',list(map(round,bst.predict(dvalid))==valid_y).count(True)/float(len(valid_y))\n",
    "print 'test score:',list(map(round,bst.predict(dtest))==test_y).count(True)/float(len(test_y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
