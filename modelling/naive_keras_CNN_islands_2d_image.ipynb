{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Very naive deep learning on the vector of surrounding bases\n",
    "\n",
    "---\n",
    "\n",
    "### Data\n",
    "\n",
    "Naive feature vectors. The original sequence of validation/test and train data does not overlap! ( but train data points can overlap with train data points, and test-validation can overlap with test-validation data ) This overlapping does not lead to unintentional label leakage!\n",
    "\n",
    "\n",
    "\n",
    "### Notes\n",
    "\n",
    "- Worse than single channel\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instruct theano to use gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['THEANO_FLAGS']='device=gpu'\n",
    "\n",
    "import sys\n",
    "sys.path.append('../my_modules')\n",
    "from loading_utils import read_my_data\n",
    "\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os,subprocess\n",
    "workdir='/mnt/Data1/ribli/methylation_code/modelling'\n",
    "subprocess.call(['mkdir',workdir])\n",
    "os.chdir(workdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data... \n",
      "Loading data... \n"
     ]
    }
   ],
   "source": [
    "train_id,train_x,train_y = read_my_data(\n",
    "    fname='../prepare_data/big_train_feat_vect.csv')\n",
    "test_id,test_x,test_y = read_my_data(\n",
    "    fname='../prepare_data/big_test_feat_vect.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "annot=pd.read_csv('../explore_data/relevant_annotations.csv',sep='\\t',header=None)\n",
    "annot.columns=['id','Regulatory_Feature_Group','Relation_to_UCSC_CpG_Island',\n",
    "    'Strand','Infinium_Design_Type','Random_Loci','Methyl27_Loci']\n",
    "annot.fillna(0,inplace=True)\n",
    "train_merged=pd.DataFrame(train_id,columns=['id']).merge(annot,on=['id'])\n",
    "test_merged=pd.DataFrame(test_id,columns=['id']).merge(annot,on=['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select inidces for islands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cg_exl_idx=np.array([x[499]==2 and x[500]==3 for x in train_x])\n",
    "annot_idx=np.array(np.zeros(len(train_x)),dtype=bool)\n",
    "annot_idx[train_merged[train_merged.Relation_to_UCSC_CpG_Island=='Island'].index]=True\n",
    "train_idx=cg_exl_idx & annot_idx\n",
    "train_idx_0=cg_exl_idx & annot_idx & (train_y ==0)\n",
    "train_idx_1=cg_exl_idx & annot_idx & (train_y ==1)\n",
    "\n",
    "\n",
    "cg_exl_idx=np.array([x[499]==2 and x[500]==3 for x in test_x])\n",
    "annot_idx=np.array(np.zeros(len(test_x)),dtype=bool)\n",
    "annot_idx[test_merged[test_merged.Relation_to_UCSC_CpG_Island=='Island'].index]=True\n",
    "test_idx=cg_exl_idx & annot_idx\n",
    "test_idx_0=cg_exl_idx & annot_idx & (test_y==0)\n",
    "test_idx_1=cg_exl_idx & annot_idx & (test_y==1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "bal_train_x=np.concatenate([train_x[train_idx_0][:np.sum(train_idx_1)],train_x[train_idx_1]])\n",
    "bal_train_y=np.concatenate([train_y[train_idx_0][:np.sum(train_idx_1)],train_y[train_idx_1]])\n",
    "\n",
    "bal_test_x=np.concatenate([test_x[test_idx_0][:np.sum(test_idx_1)],test_x[test_idx_1]])\n",
    "bal_test_y=np.concatenate([test_y[test_idx_0][:np.sum(test_idx_1)],test_y[test_idx_1]])\n",
    "\n",
    "\n",
    "#shuffle them\n",
    "#set seed to make the selection reproducible\n",
    "rng=np.random.RandomState(42)\n",
    "new_idx=rng.permutation(len(bal_train_y))\n",
    "bal_train_x=bal_train_x[new_idx]\n",
    "bal_train_y=bal_train_y[new_idx]\n",
    "\n",
    "new_idx=rng.permutation(len(bal_test_y))\n",
    "bal_test_x=bal_test_x[new_idx]\n",
    "bal_test_y=bal_test_y[new_idx]\n",
    "\n",
    "print np.mean(bal_train_y)\n",
    "print np.mean(bal_test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encode them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(np.concatenate([bal_train_x.flatten(),bal_test_x.flatten()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "one_hot_train_x=lb.transform(bal_train_x.flatten()).reshape((-1,1,1000,5))\n",
    "one_hot_test_x=lb.transform(bal_test_x.flatten()).reshape((-1,1,1000,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build convnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 670 (CNMeM is disabled, CuDNN not available)\n",
      "/mnt/Data1/ribli/tools/anaconda/lib/python2.7/site-packages/theano/tensor/signal/downsample.py:5: UserWarning: downsample module has been moved to the pool module.\n",
      "  warnings.warn(\"downsample module has been moved to the pool module.\")\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D,MaxPooling2D\n",
    "\n",
    "input_dim=one_hot_train_x.shape[2]\n",
    "activation='relu'\n",
    "loss='binary_crossentropy'\n",
    "optimizer='adadelta'\n",
    "init='uniform'\n",
    "pool_size=(8,1)\n",
    "window_size=5\n",
    "dense_n=64\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#Convolution layer 1\n",
    "model.add(Convolution2D(20,window_size,5, border_mode='valid',input_shape=(1,input_dim,5)))\n",
    "model.add(Activation(activation))\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "#Convolution layer 2\n",
    "model.add(Convolution2D(50,window_size,1, border_mode='valid'))\n",
    "model.add(Activation(activation))\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "#Dense layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(dense_n,activation=activation))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "#final layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#compile model\n",
    "model.compile(loss=loss,optimizer=optimizer,class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "def fit_keras_model(model,train_x,train_y,test_x,test_y,validation_split=0.05):\n",
    "    start=time.time()\n",
    "    \n",
    "    #callbacks\n",
    "    best_model=ModelCheckpoint('best_model',save_best_only=True,verbose=1)\n",
    "    early_stop=EarlyStopping(patience=7,verbose=1)\n",
    "    \n",
    "    #train it\n",
    "    callb_hist=model.fit(train_x,train_y,nb_epoch = 100,\n",
    "                         show_accuracy=True,verbose=1,\n",
    "                        validation_split=validation_split,\n",
    "                        callbacks=[best_model,early_stop])\n",
    "    #predict\n",
    "    model.load_weights('best_model')\n",
    "    train_pred=model.predict_classes(train_x).ravel()\n",
    "    test_pred=model.predict_classes(test_x).ravel()\n",
    "    \n",
    "    train_pred_pr=model.predict(train_x).ravel()\n",
    "    test_pred_pr=model.predict(test_x).ravel()\n",
    "\n",
    "    #check errors\n",
    "    print 'train accuracy:',list((train_pred==train_y)).count(True)/float(len(train_y))\n",
    "    print 'test accuracy:',list((test_pred==test_y)).count(True)/float(len(test_y))\n",
    "\n",
    "    print 'It took:',time.time()-start    \n",
    "    return train_pred,test_pred,train_pred_pr,test_pred_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17651 samples, validate on 4413 samples\n",
      "Epoch 1/100\n",
      "17651/17651 [==============================] - 8s - loss: 0.6759 - acc: 0.6153 - val_loss: 0.5737 - val_acc: 0.7729\n",
      "Epoch 00000: val_loss improved from inf to 0.57365, saving model to best_model\n",
      "Epoch 2/100\n",
      "17651/17651 [==============================] - 8s - loss: 0.5254 - acc: 0.7491 - val_loss: 0.4324 - val_acc: 0.8192\n",
      "Epoch 00001: val_loss improved from 0.57365 to 0.43238, saving model to best_model\n",
      "Epoch 3/100\n",
      "17651/17651 [==============================] - 8s - loss: 0.4432 - acc: 0.8003 - val_loss: 0.3730 - val_acc: 0.8362\n",
      "Epoch 00002: val_loss improved from 0.43238 to 0.37295, saving model to best_model\n",
      "Epoch 4/100\n",
      "17651/17651 [==============================] - 8s - loss: 0.3949 - acc: 0.8243 - val_loss: 0.3224 - val_acc: 0.8622\n",
      "Epoch 00003: val_loss improved from 0.37295 to 0.32240, saving model to best_model\n",
      "Epoch 5/100\n",
      "17651/17651 [==============================] - 8s - loss: 0.3490 - acc: 0.8500 - val_loss: 0.3181 - val_acc: 0.8672\n",
      "Epoch 00004: val_loss improved from 0.32240 to 0.31811, saving model to best_model\n",
      "Epoch 6/100\n",
      "17651/17651 [==============================] - 8s - loss: 0.3224 - acc: 0.8637 - val_loss: 0.3316 - val_acc: 0.8584\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 7/100\n",
      "17651/17651 [==============================] - 8s - loss: 0.3057 - acc: 0.8704 - val_loss: 0.2951 - val_acc: 0.8783\n",
      "Epoch 00006: val_loss improved from 0.31811 to 0.29507, saving model to best_model\n",
      "Epoch 8/100\n",
      "17651/17651 [==============================] - 8s - loss: 0.2895 - acc: 0.8784 - val_loss: 0.2904 - val_acc: 0.8760\n",
      "Epoch 00007: val_loss improved from 0.29507 to 0.29045, saving model to best_model\n",
      "Epoch 9/100\n",
      "17651/17651 [==============================] - 8s - loss: 0.2725 - acc: 0.8884 - val_loss: 0.2591 - val_acc: 0.8942\n",
      "Epoch 00008: val_loss improved from 0.29045 to 0.25910, saving model to best_model\n",
      "Epoch 10/100\n",
      "17651/17651 [==============================] - 8s - loss: 0.2608 - acc: 0.8958 - val_loss: 0.3174 - val_acc: 0.8695\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 11/100\n",
      "17651/17651 [==============================] - 8s - loss: 0.2542 - acc: 0.8949 - val_loss: 0.2666 - val_acc: 0.8915\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 12/100\n",
      "17651/17651 [==============================] - 8s - loss: 0.2396 - acc: 0.9038 - val_loss: 0.2587 - val_acc: 0.8987\n",
      "Epoch 00011: val_loss improved from 0.25910 to 0.25871, saving model to best_model\n",
      "Epoch 13/100\n",
      "17651/17651 [==============================] - 8s - loss: 0.2299 - acc: 0.9048 - val_loss: 0.2806 - val_acc: 0.8869\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 14/100\n",
      "17651/17651 [==============================] - 8s - loss: 0.2186 - acc: 0.9099 - val_loss: 0.2629 - val_acc: 0.8978\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 15/100\n",
      "17651/17651 [==============================] - 8s - loss: 0.2083 - acc: 0.9176 - val_loss: 0.3068 - val_acc: 0.8733\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 16/100\n",
      "17651/17651 [==============================] - 8s - loss: 0.1986 - acc: 0.9203 - val_loss: 0.3432 - val_acc: 0.8692\n",
      "Epoch 00015: val_loss did not improve\n",
      "Epoch 17/100\n",
      "17651/17651 [==============================] - 8s - loss: 0.1791 - acc: 0.9286 - val_loss: 0.2742 - val_acc: 0.8944\n",
      "Epoch 00016: val_loss did not improve\n",
      "Epoch 18/100\n",
      "17651/17651 [==============================] - 8s - loss: 0.1680 - acc: 0.9340 - val_loss: 0.2876 - val_acc: 0.8930\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 19/100\n",
      "17651/17651 [==============================] - 8s - loss: 0.1500 - acc: 0.9390 - val_loss: 0.2964 - val_acc: 0.8926\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 20/100\n",
      "17651/17651 [==============================] - 8s - loss: 0.1278 - acc: 0.9514 - val_loss: 0.3269 - val_acc: 0.8867\n",
      "Epoch 00019: val_loss did not improve\n",
      "Epoch 00019: early stopping\n",
      "22064/22064 [==============================] - 4s     \n",
      "1010/1010 [==============================] - 0s     \n",
      "train accuracy: 0.921002538071\n",
      "test accuracy: 0.883168316832\n",
      "It took: 173.806463957\n",
      "\n",
      "prediction balance:\n",
      "0.469044597534\n",
      "0.468316831683\n"
     ]
    }
   ],
   "source": [
    "train_pred,test_pred,train_pred_pr,test_pred_pr=fit_keras_model(\n",
    "    model,one_hot_train_x,bal_train_y,one_hot_test_x,bal_test_y,validation_split=0.2)\n",
    "\n",
    "print '\\nprediction balance:'\n",
    "print np.mean(train_pred)\n",
    "print np.mean(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import metrics\n",
    "def plot_roc(y,probs):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y,probs)\n",
    "    auc=metrics.roc_auc_score(y,probs)\n",
    "    \n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.plot(fpr,tpr,lw=2)\n",
    "    plt.plot([0,1],[0,1],lw=2)\n",
    "    plt.xlim(-0.01,1.01)\n",
    "    plt.ylim(-0.01,1.01)\n",
    "    plt.xlabel('FP rate')\n",
    "    plt.ylabel('TP rate')\n",
    "    print 'auc:',auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc: 0.949906871875\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAGCCAYAAAAR7+9DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJI1kLCRJIxkLSdJI/x+cLj1Z7mL6agAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f534ccdf990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc(bal_test_y,test_pred_pr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
